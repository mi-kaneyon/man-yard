{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e43a09-7f5d-4967-ae8e-c848b0c64732",
   "metadata": {},
   "source": [
    "# CAT My favorite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8330f9d7-044b-4a60-822e-53b55e683a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize the DeepLab model and move it to CUDA\n",
    "model = models.segmentation.deeplabv3_resnet101(pretrained=True).to('cuda')\n",
    "model.eval()\n",
    "\n",
    "# Initialize camera and set FPS\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "\n",
    "# Initialize variables\n",
    "num_clones = 0\n",
    "alpha = 0.5  # Transparency level\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for model\n",
    "    input_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0).to('cuda')\n",
    "\n",
    "    # Run the frame through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)['out'][0]\n",
    "    output_predictions = torch.argmax(output, dim=0).byte().cpu().numpy()\n",
    "\n",
    "    # Create mask and clones\n",
    "    mask = (output_predictions == 8)\n",
    "    masked_frame = np.zeros_like(frame)\n",
    "    masked_frame[mask] = frame[mask]\n",
    "\n",
    "    final_frame = np.copy(frame)\n",
    "    h, w, _ = frame.shape\n",
    "    offsets = np.linspace(-w // 4, w // 4, num_clones)\n",
    "\n",
    "    for offset in offsets:\n",
    "        translation_matrix = np.float32([[1, 0, offset], [0, 1, 0]])\n",
    "        clone = cv2.warpAffine(masked_frame, translation_matrix, (w, h))\n",
    "\n",
    "        mask_clone = clone > 0\n",
    "\n",
    "        # Check if the mask_clone has any True values before proceeding\n",
    "        if np.any(mask_clone):\n",
    "            rows, cols, _ = np.where(mask_clone)\n",
    "            for r, c in zip(rows, cols):\n",
    "                temp_final = final_frame[r, c][np.newaxis, :]\n",
    "                temp_clone = clone[r, c][np.newaxis, :]\n",
    "                final_frame[r, c] = cv2.addWeighted(temp_final, 1 - alpha, temp_clone, alpha, 0).flatten()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Cat Cloner', final_frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    # Increase or decrease the number of clones\n",
    "    if key == ord('A') or key == ord('a'):\n",
    "        num_clones = min(num_clones + 1, 5)\n",
    "    elif key == ord('D') or key == ord('d'):\n",
    "        num_clones = max(num_clones - 1, 0)\n",
    "    elif key == ord('Q') or key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe88df7-8279-4bc5-bdcb-91c403774855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab8038-851d-4ce9-8a31-401e1744d57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
